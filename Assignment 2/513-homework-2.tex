\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsfonts}
\begin{document}
\pagestyle{headings}
\markright{Design and Analysis of Algorithms}
\centerline{Eric Bronner, Aedan Dispenza, Jason Davis, Timothy Yong}
\centerline{CS513 - Dr. Farach-Colton}
\centerline{\underline{Homework 2}}
\noindent \underline{Problem 1}\\
\centerline{\underline{Algorithm:}}\\
1. Sort the first $k$ elements with merge sort\\ 
2. Perform insertion sort on previous $k-1$ elements based on binary search\\
\indent $k-1$, because, once the first $k$ elements are sorted,\\ 
\indent the first element must be in the correct spot.\\
\indent We ignore one more element per each iteration.\\
\centerline{\underline{Proof of Correctness by Contradiction:}}\\
Assume $\exists a \in A$, where $A$ is the $k$-sorted array post-sort, s.t. $a$ is not sorted.\\
Case 1: $a$ is within range of the previous $k-1$ elements\\
\indent Either merge sort or insertion sort must have failed.\\
\indent This is a contradiction, as merge sort and insertion sort do not fail.\\
Case 2: $a$ is not within $k$ elements of where it started\\
\indent This is a contradiction, as this means that $a$ was not $k$-sorted to begin\\
Therefore, $a$ cannot exist, and the algorithm must work $\square$\\
\centerline{\underline{Running-Time Analysis:}}\\
Merge sorting the first $k$ elements will take $klog{k}$ time\\
Binary search-based insertion sort for $n-k$ elements will take\\
\indent $(n-k)log{(k-1)}$ time\\  
In total, the running time is $klog{k} + nlog{k} - klog{(k-1)}$\\
Therefore, the running time is $O(nlog{k})$, as $n \geq k$\\
\underline{Problem 2}\\
Suppose we have a k-sorted array $A$\\
For every element $a \in A$ there are $k$ possible placements in $n$ total bins\\
So the number of posssibilities is $\prod_{i = 0}^{n} k = k^n$\\
If we take the logarithm of this (because of the decision tree), we get:\\
\indent $log(k^n) = nlog(k)$\\
So it's $\Omega(nlog(k))$\\
\underline{Problem 3}\\
a) Suppose we have two subtrees, $l$ and $h$ of a tree $T$, where $l$ is the lighter\\
\indent subtree, $h$ is the heavier subtree and $w(h) = 2 \times w(l) + 1$. The number\\
\indent of nodes in the tree is $n$, so there are $n-3$ nodes beneath the root and\\
\indent its children.\\
\begin{center}
$w(h) = 2w(l) + 1$\\
$n - 3 = 2w(l) + 1 + w(l)$\\
$n - 3 = 3w(l) + 1$\\
$\frac{n - 4}{3} = w(l)$\\
\end{center}
\indent\indent So this means that $w(l) = \frac{n - 4}{3}$ and $w(h) = \frac{2n - 8}{3} + 1$\\
\indent Thus, $h(h) = log{(\frac{2n-8}{3} + 1)}$ and $h(l) = log{(\frac{n - 4}{3})}$\\
\indent So, we have $O(logn)$ time to search both subtrees.\\
\indent Adding the 3 removed nodes only adds a constant factor.\\
b) Suppose we have a tree $T$, s.t. $T$ is the bare minimum tree that maintains\\
\indent the balance property, without the two subtrees being of equal weight.\\
\indent If we add another node to $h$, then we would rebuild the subtree all the\\
\indent way up to the root via AVL rotation.\\
\indent This rotation takes $O(log(n))$ time due to $T$ having $log(n)$ levels.\\
c) 1 or 2 insertions are required to unbalance a freshly balanced tree.\\
\indent It is 1 insertion if one subtree is complete, 2 in any other case.\\
d) The probability of unbalancing the tree in the worst case scenario\\
\indent\indent is $\frac{1}{n}log(n)$\\
\indent The number of nodes we need to add unbalance the tree again after\\
\indent \indent rebalancing is $\sum_{i=0}^{log(n)} \frac{n}{2^i} = 2n$\\
\indent So, the worst case cost of unbalancing and rebalancing the tree is $2nlog(n)$.\\
\indent The cost to insert all nodes that do not lead to a worst case is $n-log(n)$.\\
\indent So, the cost of $n$ insertions is $nlogn + (n  - log(n))$, or $O(nlog(n))$.\\
e) The amortized cost is $\frac{nlog(n)}{n} = O(logn)$\\
\underline{Problem 4}\\
\underline{Proof by Induction:}\\
Base: $\exists$ only one column\\
\indent The row is sorted by definition and default, as it's length is $1$\\
\indent So, if we sort vertically, nothing can change.\\
Inductive Hypothesis: \\
\indent Assume that for some number of sorted columns $\leq n$, we can\\
\indent\indent maintain horizontal sort after vertically sorting.\\
Inductive Step:\\
\indent Add a new column (the $n+1^{th}$), keeping the rows sorted\\
\indent Sort the new column; compare the new element at position $i$\\
\indent\indent to the element that was previously there.\\
\indent Case 1: Element is the same\\
\indent\indent Nothing has changed; the row must still be sorted.\\
\indent Case 2: Position $i$ now holds a greater value\\
\indent\indent Because the rows up to column $n$ are still sorted, and\\ 
\indent\indent\indent the value in position $i$ has only increased, the row must be sorted\\
\indent Case 3: Position $i$ now holds a smaller value, $x$\\
\indent\indent $x$ originated elsewhere in the column\\
\indent\indent $x$ must belong at position $i$, proven by contradiction:\\
\indent\indent\indent Assume $x$ is less than the value in the column next to it, same row\\
\indent\indent\indent If try to resort $x$ by moving it up in the column, two cases emerge:\\
\indent\indent\indent Case 1: $x$ is always less than the value in the before it\\
\indent\indent\indent\indent This is a contradiction, as $x$ doesn't belong in this column,\\
\indent\indent\indent\indent since the rows were originally sorted\\
\indent\indent\indent Case 2: We find a new place for $x$\\
\indent\indent\indent\indent We must have displaced another element, $y$ s.t. $y < x$\\
\indent\indent\indent\indent But, because $y$ is less than everything below it,\\ 
\indent\indent\indent\indent\indent as we've already sorted the column,\\ 
\indent\indent\indent\indent\indent we have a new out-of-place element\\
\indent\indent\indent\indent Therefore, we have a contradiction $\square$\\
\underline{Problem 5}\\
Say we have a graph $G$\\
We will call HamP on every pair of nodes in $G$.\\
If HamP returns true for any pair of nodes and those two nodes are\\
\indent connected, then we have found a Hamiltonian Cycle\\
This process will take $O(n^2) \in P$\\
\underline{Problem 6}\\
Say we have a graph $G$\\
If we call HamP on every of nodes in G, we will either find a Hamiltonian\\ 
\indent Path or find that there is none.\\
This algorithm will take $\frac{n(n-1)}{2}$  or $O(n^2) \in P$
\end{document}